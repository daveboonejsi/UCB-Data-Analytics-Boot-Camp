# UCB Data Analytics Bootcamp, 2020

## Final Project Self Assessment

1.	Self Assessment
I contributed to the project by conceiving the idea for assessing preparedness for infection control and prevention in health facilities in developing countries.  Through my work I have knowledge of, and access to, data on the performance of health facilities in developing countries.  The group liked the idea and we went with it.  
I obtained the data from the organization that maintains it, and did the initial preprocessing by extracting and recoding pertinent variables using SPSS.   I also obtained demographic and health data for the four countries, and GPS data for the facilities sampled for the assessments we would be using.  I merged the data files for four different countries and submitted to our Slack group thread. 
For the project I took on the role of Machine Learning Analyst.  I selected the model to be used, supervised machine learning classification model which predicted readiness for infection control and prevention.  I also suggested the methodology for creating the outcome variable, and the potential predicators based on my knowledge of the datasets and infection control practice.
I also contributed to other areas of the project by suggesting visuals for the dashboard, reviewing output for the dashboard, and suggesting fixes and improvements.  I contributed to the presentation by suggesting points of emphasis and summarizing the strengths and weaknesses of our approach. 
The greatest personal challenge I had was getting the models to run given the nature of the data.  We had an issue where the logistic regression model wouldn’t converge since some of the data were continuous with large values relative to other predictors.  Also, our outcome variable was imbalanced with a very small minority class relative to the majority class.  I overcame these difficulties by scaling the data and oversampling.  I also had a problem dealing with missing data and my solution was probably overkill.  I used dropna() in a universal fashion where a more precise targeting and handling of the missing values might have preserved more of the data.

2.	Team Assessment
The team was thrown together randomly.  The online course doesn’t really lend itself to getting to know the other classmates and so we were all getting to know each other in the group project.  That said, all the team members were eager to participate and contribute as they could.  We had just enough of the right amount of knowledge, expertise, and effort to pull it off.  We met several times outside of the class schedule to coordinate, using Zoom.  While not everyone made all of these supplemental meetings, enough of us met enough times to get the job done.  It was hard to coordinate five people who all have families and jobs and other things competing for attention. The communication methods, particularly Slack, were very helpful at keeping everyone on point.
One challenge was trying to balance the workload among the participants.  Some of the roles are just not as demanding as others.  For example, the project manager position is somewhat of a light lift compared to the other roles.  However, in the end, all the participants contributed significantly and were eager to participate.  The experience was really positive and I was impressed with everyone’s willingness to go the extra mile to help out.

3.	Project Summary
We used a supervised machine learning classification model to predict whether health facilities in select developing countries are prepared or not to provide services safely in light of the global pandemic of COVID19.  We modeled preparedness using predicators such as availability of personal protective equipment, disinfectant, clean water sources, and various facility characteristics and attributes of service delivery.  Logistic regression, Support Vector Machines, Decision Tress, and Gradient Boosted Tree models were all employed, and data were scaled and oversampled to improve model performance.  While the balanced accuracy of the models was acceptable (0.75), the accuracy, precision, recall and F1 scores of the minority class (prepared for infection control) were too weak to conclude that models are useful for predicting preparedness.
